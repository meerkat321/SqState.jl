using JLD2
using TransformVariables
using LogDensityProblems
using DynamicHMC
using Parameters
using Statistics
using Random
using ForwardDiff
using Distributions

export
    pdf,
    pdf!,
    gen_nongaussian_training_data,
    gen_gaussian_training_data,
    gen_gaussian_training_data!

real_tr_mul(ğš, ğ›) = sum(real(ğš[i, :]' * ğ›[:, i]) for i in 1:size(ğš, 1))

function pdf(state::StateMatrix, Î¸::Real, x::Real)
    return real_tr_mul(ğ›‘Ì‚(Î¸, x, dim=state.dim), state.ğ›’)
end

function pdf(state::StateMatrix, Î¸s, xs; T=Float64)
    ğ© = Matrix{T}(undef, length(Î¸s), length(xs))

    return pdf!(ğ©, state, Î¸s, xs)
end

function pdf!(ğ©::Matrix{T}, state::StateMatrix, Î¸s, xs) where {T}
    ğ›‘Ì‚_res = Matrix{complex(T)}(undef, state.dim, state.dim)

    for (j, x) in enumerate(xs)
        for (i, Î¸) in enumerate(Î¸s)
            ğ©[i, j] = real_tr_mul(ğ›‘Ì‚!(ğ›‘Ì‚_res, Î¸, x; dim=state.dim), state.ğ›’)
        end
    end

    return ğ©
end

struct QuantumStateProblem
    state::StateMatrix
end

function (problem::QuantumStateProblem)(ğ±)
    @unpack Î¸, x = ğ±
    @unpack state = problem

    Ïˆâ‚™s = Ïˆâ‚™.(0:state.dim-1, Î¸, x)
    p = real_tr_mul(Ïˆâ‚™s*Ïˆâ‚™s', state.ğ›’)
    p = (p <= 0) ? floatmin() : p

    return log(p)
end

function gen_nongaussian_training_data(state::StateMatrix; n::Integer=40960, Î¸_range::Tuple=(0., 2Ï€), x_range=(-20., 20.))
    second = arr -> arr[2]
    t = as((Î¸=as(Real,Î¸_range[1], Î¸_range[2]), x=as(Real, x_range[1], x_range[2])))

    problem = QuantumStateProblem(state)

    log_likelyhood = TransformedLogDensity(t, problem)
    âˆ‡log_likelyhood = ADgradient(:ForwardDiff, log_likelyhood)

    results = mcmc_with_warmup(Random.GLOBAL_RNG, âˆ‡log_likelyhood, n)
    sampled_data = transform.(t, results.chain)

    return hcat(first.(sampled_data), second.(sampled_data)), results
end

function gen_gaussian_training_data(state::StateMatrix, n::Integer; bias_phase=0)
    points = Vector{Float64}(undef, n)

    return gen_gaussian_training_data!(points, state, bias_phase)
end

function gen_gaussian_training_data!(
    points::AbstractVector{Float64},
    state::StateMatrix, bias_phase::Float64
)
    n = length(points)

    # Î¸s
    view(points, :) .= sort!(2Ï€*rand(n) .+ bias_phase)

    # Î¼ and Ïƒ given Î¸
    Î¼ = Î”Ï€Ì‚â‚“(view(points, :), state)
    Ïƒ = real(sqrt.(Î”Ï€Ì‚â‚“Â²(view(points, :), state) - Î¼.^2))

    # xs
    view(points, :) .= real(Î¼) + Ïƒ .* randn(n)

    return points
end
