using JLD2
using TransformVariables
using LogDensityProblems
using DynamicHMC
using Parameters
using Statistics
using Random
using ForwardDiff
using KernelDensity

export
    pdf,
    pdf!,
    DHMC,
    Rejection,
    gen_nongaussian_training_data,
    gen_gaussian_training_data,
    gen_gaussian_training_data!

#######
# pdf #
#######

real_tr_mul(ğš, ğ›) = sum(real(ğš[i, :]' * ğ›[:, i]) for i in 1:size(ğš, 1))

function pdf(state::StateMatrix, Î¸::Real, x::Real)
    return real_tr_mul(ğ›‘Ì‚(Î¸, x, dim=state.dim), state.ğ›’)
end

function pdf(state::StateMatrix, Î¸s, xs; T=Float64)
    ğ© = Matrix{T}(undef, length(Î¸s), length(xs))

    return pdf!(ğ©, state, Î¸s, xs)
end

function pdf!(ğ©::Matrix{T}, state::StateMatrix, Î¸s, xs) where {T}
    ğ›‘Ì‚_res = Matrix{complex(T)}(undef, state.dim, state.dim)

    for (j, x) in enumerate(xs)
        for (i, Î¸) in enumerate(Î¸s)
            ğ©[i, j] = real_tr_mul(ğ›‘Ì‚!(ğ›‘Ì‚_res, Î¸, x; dim=state.dim), state.ğ›’)
        end
    end

    return ğ©
end

##############################
# nongaussian data generator #
##############################

abstract type AbstractSamplingMethod end

struct DHMC <: AbstractSamplingMethod end

struct Rejection <: AbstractSamplingMethod end

struct QuantumStateProblem
    state::StateMatrix
end

function (problem::QuantumStateProblem)(ğ±)
    @unpack Î¸, x = ğ±
    @unpack state = problem

    Ïˆâ‚™s = Ïˆâ‚™.(0:state.dim-1, Î¸, x)
    p = real_tr_mul(Ïˆâ‚™s*Ïˆâ‚™s', state.ğ›’)
    p = (p <= 0) ? floatmin() : p

    return log(p)
end

function gen_nongaussian_training_data(
    state::StateMatrix, ::DHMC;
    n::Integer=40960, Î¸_range::Tuple=(0., 2Ï€), x_range=(-10., 10.)
)
    second = arr -> arr[2]
    t = as((Î¸=as(Real, Î¸_range...), x=as(Real, x_range...)))

    problem = QuantumStateProblem(state)

    log_likelyhood = TransformedLogDensity(t, problem)
    âˆ‡log_likelyhood = ADgradient(:ForwardDiff, log_likelyhood)

    results = mcmc_with_warmup(Random.GLOBAL_RNG, âˆ‡log_likelyhood, n)
    sampled_data = transform.(t, results.chain)

    return hcat(first.(sampled_data), second.(sampled_data)), results
end

function rand2range(rand::T, range::Tuple{T, T}) where {T <: Number}
    return range[1] + (range[2]-range[1]) * rand
end

function rand2range(rand::Vector{T}, range::Tuple{T, T}) where {T <: Number}
    return range[1] .+ (range[2]-range[1]) * rand
end

function gen_nongaussian_training_data(
    state::StateMatrix, ::Rejection;
    n::Integer=40960, c=0.9, times=10, kde_result=nothing,
    Î¸_range::Tuple=(0., 2Ï€), x_range=(-10., 10.)
)
    if isnothing(kde_result)
        kde_result = kde((rand2range(rand(n),Î¸_range), rand2range(rand(n), x_range)))
    end

    p = (Î¸, x) -> pdf(state, Î¸, x)
    g = (Î¸, x) -> KernelDensity.pdf(kde_result, Î¸, x)
    data = Matrix{Float64}(undef, n, 2)
    for i in 1:times
        @info "iter: $(i)"

        splock = Threads.SpinLock()
        @time Threads.@threads for j in 1:n
            new_data = [rand2range(rand(),Î¸_range), rand2range(rand(), x_range)]
            while p(new_data...) / g(new_data...) < c
                new_data = [rand2range(rand(),Î¸_range), rand2range(rand(), x_range)]
            end

            lock(splock) do
                data[j, :] = new_data
            end
        end

        kde_result = kde((data[:, 1], data[:, 2]))
        g = (Î¸, x) -> KernelDensity.pdf(kde_result, Î¸, x)
    end

    return data, kde_result
end

###########################
# gaussian data generator #
###########################

function gen_gaussian_training_data(state::StateMatrix, n::Integer; bias_phase=0)
    points = Vector{Float64}(undef, n)

    return gen_gaussian_training_data!(points, state, bias_phase)
end

function gen_gaussian_training_data!(
    points::AbstractVector{Float64},
    state::StateMatrix, bias_phase::Float64
)
    n = length(points)

    # Î¸s
    view(points, :) .= sort!(2Ï€*rand(n) .+ bias_phase)

    # Î¼ and Ïƒ given Î¸
    Î¼ = Î”Ï€Ì‚â‚“(view(points, :), state)
    Ïƒ = real(sqrt.(Î”Ï€Ì‚â‚“Â²(view(points, :), state) - Î¼.^2))

    # xs
    view(points, :) .= real(Î¼) + Ïƒ .* randn(n)

    return points
end
