export train

function update_model!(model_file_path, model)
    model = cpu(model)
    jldsave(model_file_path; model)
    @warn "model updated!"
end

function train(model_name::String; epochs=10, Î·â‚€=1e-2, batch_size=25, n_validation_batch=100)
    if has_cuda()
        @info "CUDA is on"
        device = gpu
        CUDA.allowscalar(false)
    else
        device = cpu
    end

    m = model() |> device
    loss(x, y) = Flux.mse(m(x), y)
    opt = Flux.Optimiser(WeightDecay(1e-4), Flux.Momentum(Î·â‚€, 0.9))

    # prepare data
    data_file_names = filter(x->x!=".gitkeep", readdir(SqState.training_data_path()))
    loader_test = preprocess_q2args(data_file_names[1], batch_size=batch_size)
    @info "numbers of data fragments: $(length(data_file_names)-1)"
    data_loaders = Channel(5, spawn=true) do ch
        for e in 1:epochs, (i, file_name) in enumerate(data_file_names[2:end])
            put!(ch, preprocess_q2args(file_name, batch_size=batch_size))
            @info "Load epoch $e, file $i into buffer"
        end
    end

    t = 1
    losses = Float32[]
    data_validation = [(ð±, ð²) for (ð±, ð²) in loader_test][1:n_validation_batch] |> device
    function validate()
        validation_loss = sum(loss(ð±, ð²) for (ð±, ð²) in data_validation)/length(data_validation)
        @info "$(t)0k data\n Î·: $(opt.os[2].eta)\n loss: $validation_loss"

        push!(losses, validation_loss)
        (losses[end] == minimum(losses)) && update_model!(joinpath(model_path(), "$model_name.jld2"), m)
    end
    call_back = Flux.throttle(validate, 20, leading=false, trailing=true)

    for loader_train in data_loaders
        data = [(ð±, ð²) for (ð±, ð²) in loader_train] |> device
        @time Flux.train!(loss, params(m), data, opt, cb=call_back)
        (t > 50) && (opt.os[2].eta = 1e-2 / 2^ceil((t-50)/30))
        t += 1
    end
end
